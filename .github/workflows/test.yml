name: Tests & Coverage (Reusable - Python)

on:
  workflow_call:
    inputs:
      python-version:
        required: false
        type: string
        default: "3.12"
      coverage-min:
        required: false
        type: number
        default: 60
        description: "Porcentaje minimo de coverage requerido"
      skip-tests:
        required: false
        type: boolean
        default: false
        description: "Saltar la ejecucion de tests"
    outputs:
      coverage_percent:
        description: "Porcentaje de coverage"
        value: ${{ jobs.python-tests.outputs.coverage_percent }}
      tests_passed:
        description: "Numero de tests que pasaron"
        value: ${{ jobs.python-tests.outputs.tests_passed }}
      tests_failed:
        description: "Numero de tests que fallaron"
        value: ${{ jobs.python-tests.outputs.tests_failed }}
      pytest_outcome:
        description: "Resultado de pytest"
        value: ${{ jobs.python-tests.outputs.pytest_outcome }}
      has_critical_errors:
        description: "Si hay errores criticos"
        value: ${{ jobs.python-tests.outputs.has_critical_errors }}
      coverage_ok:
        description: "Si el coverage cumple con el minimo"
        value: ${{ jobs.python-tests.outputs.coverage_ok }}

permissions:
  contents: read
  pull-requests: write

jobs:
  python-tests:
    name: Python Tests & Coverage
    runs-on: ubuntu-latest
    if: ${{ !inputs.skip-tests }}
    outputs:
      coverage_percent: ${{ steps.pytest.outputs.coverage_percent }}
      tests_passed: ${{ steps.pytest.outputs.tests_passed }}
      tests_failed: ${{ steps.pytest.outputs.tests_failed }}
      pytest_outcome: ${{ steps.pytest.outcome }}
      has_critical_errors: ${{ steps.pytest.outputs.has_critical_errors }}
      coverage_ok: ${{ steps.pytest.outputs.coverage_ok }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version }}
          cache: "pip"

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
          pip install pytest pytest-cov

      - name: Run Python tests with coverage
        id: pytest
        continue-on-error: true
        run: |
          set +e
          pytest --cov=. --cov-report=term --cov-report=html --cov-report=xml -v > pytest-output.txt 2>&1
          PYTEST_EXIT=$?
          set -e

          cat pytest-output.txt

          # Inicializar variables
          HAS_CRITICAL_ERRORS="false"
          COVERAGE_OK="false"

          # Extraer estadisticas de coverage
          if [ -f "coverage.xml" ]; then
            COVERAGE=$(grep -oP 'line-rate="\K[0-9.]+' coverage.xml | head -1 || echo "0")
            COVERAGE_PERCENT=$(echo "$COVERAGE * 100" | bc | cut -d. -f1)
            echo "coverage_percent=$COVERAGE_PERCENT" >> $GITHUB_OUTPUT
            echo "Cobertura: ${COVERAGE_PERCENT}%"

            # Validar coverage minimo
            if [ "$COVERAGE_PERCENT" -ge ${{ inputs.coverage-min }} ]; then
              echo "Coverage OK (${COVERAGE_PERCENT}% >= ${{ inputs.coverage-min }}%)"
              COVERAGE_OK="true"
            else
              echo "Coverage bajo (${COVERAGE_PERCENT}% < ${{ inputs.coverage-min }}%)"
              echo "::error::CRITICO: Coverage insuficiente (${COVERAGE_PERCENT}% < ${{ inputs.coverage-min }}%). Ver detalles en artifacts: python-coverage-report"
              COVERAGE_OK="false"
            fi
          else
            echo "No se genero reporte de coverage"
            echo "coverage_percent=0" >> $GITHUB_OUTPUT
            COVERAGE_OK="false"
          fi

          echo "coverage_ok=$COVERAGE_OK" >> $GITHUB_OUTPUT

          # Extraer estadisticas de tests
          TESTS_PASSED=$(grep -oP '\d+(?= passed)' pytest-output.txt | head -1 || echo "0")
          TESTS_FAILED=$(grep -oP '\d+(?= failed)' pytest-output.txt | head -1 || echo "0")
          echo "tests_passed=$TESTS_PASSED" >> $GITHUB_OUTPUT
          echo "tests_failed=$TESTS_FAILED" >> $GITHUB_OUTPUT
          echo "Tests: $TESTS_PASSED passed | $TESTS_FAILED failed"

          # Detectar errores criticos (FAILED con ERROR, Exception, etc.)
          if grep -iE "(FAILED.*ERROR|Exception|Critical|Fatal|Segmentation fault)" pytest-output.txt | grep -vE "(test/|tests/|_test\.py|test_.*\.py)" > critical-errors-filtered.txt 2>/dev/null && [ -s critical-errors-filtered.txt ]; then
            echo "Detectados errores CRITICOS en codigo de produccion (fuera de tests)"
            CRITICAL_LINES=$(head -5 critical-errors-filtered.txt)
            echo "::error::CRITICO: Codigo de produccion contiene errores criticos:%0A${CRITICAL_LINES//$'\n'/%0A}%0A%0AVer detalles completos en artifacts: python-logs"
            HAS_CRITICAL_ERRORS="true"
          else
            echo "No se detectaron errores criticos en codigo de produccion"
            HAS_CRITICAL_ERRORS="false"
          fi

          echo "has_critical_errors=$HAS_CRITICAL_ERRORS" >> $GITHUB_OUTPUT

          # Resultado final
          if [ "$HAS_CRITICAL_ERRORS" == "true" ]; then
            echo "FALLA: Hay errores criticos en codigo de produccion"
            exit 1
          elif [ "$COVERAGE_OK" == "false" ]; then
            echo "FALLA: Coverage insuficiente (< ${{ inputs.coverage-min }}%)"
            exit 1
          elif [ $PYTEST_EXIT -eq 0 ]; then
            echo "Todos los tests pasaron"
            exit 0
          elif [ $PYTEST_EXIT -eq 5 ]; then
            echo "No se encontraron tests"
            echo "::warning::No se encontraron tests. Considera agregar tests a tu proyecto."
            exit 0
          else
            echo "Algunos tests fallaron, pero sin errores criticos y coverage OK"
            echo "El build puede continuar"
            exit 0
          fi

      - name: Check coverage directory
        if: always() && steps.pytest.outcome != 'skipped'
        run: |
          if [ -d "htmlcov" ] || [ -f "coverage.xml" ]; then
            echo "Reportes de coverage encontrados"
            ls -lah htmlcov/ coverage.xml .coverage 2>/dev/null || true
          else
            echo "::warning::No se generaron reportes de coverage. Verifica pytest-cov en las dependencias."
          fi

      - name: Upload coverage reports
        if: always() && steps.pytest.outcome != 'skipped'
        uses: actions/upload-artifact@v4
        with:
          name: python-coverage-report-${{ github.run_id }}
          path: |
            htmlcov/
            coverage.xml
            .coverage
          retention-days: 7
          if-no-files-found: warn

      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: python-logs-${{ github.run_id }}
          path: pytest-output.txt
          retention-days: 7
          if-no-files-found: ignore

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: python-build-artifacts-${{ github.run_id }}
          path: dist/

      - name: Upload package artifacts (conditional)
        if: steps.pytest.outputs.coverage_ok == 'true' && steps.pytest.outputs.has_critical_errors == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: python-package-${{ github.run_id }}
          path: dist/
          retention-days: 30
          if-no-files-found: warn
